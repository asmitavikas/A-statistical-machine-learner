Q1. When is it safe to assume "normal" distribution.
A1. CLT states that when the sample sizes are large enough, sample means tend to have normal distributions. N=30 is a valid lower bound on sample size. We can also build the model and then plot QQ plots or apply Shapiro-Wilk or Kolmogrov-Smirnov's test to find normality.

Q2. if confidence interval of two groups is [-10,-8] how would  you explain it? (Google)
A2. Assume confidence interval of two groups = confidence interval of difference in data between two groups
	Let us take the confidence level = 95%. 
	We are 95% confident that the mean of the difference between two groups lies between -10 and -8.
	Mean would be -9 and standard error around 1/2

Q3. Explain confidence interval to someone without a statistics background
A3. Confidence intervals capture how confident we are about a particular value. If we're not confident, the interval will be large. It's like we're saying, "I think this is the right value, but it could be as low as this or as high as this. We're not very confident in it". If the confidence interval is high, it's because we have a small sample size, a lot of variation, or both.

Q4. Bootstrap resampling?
A4. Bootstrapping is a statistical method that uses data resampling with replacement (see: generate_sample_indices) to estimate the robust properties of nearly any statistic.

Q5. What is p-value?
A5. P-value is essentially the probability of rejecting the null hypothesis. And how do we reject the null hypothesis? By observing samples beyond the scope of null hypothesis. Thus P-value is the probability of observing samples more extreme than our data, given null hypothesis is true.
	Small p-value = reject null hypothesis


Q6. What is the difference between Bayesian Estimate and Maximum Likelihood Estimation (MLE)?
A6. In bayesian estimate we have some knowledge about the data/problem (prior) .There may be several values of the parameters which explain data and hence we can look for multiple parameters like 5 gammas and 5 lambdas that do this. So we need with prior and posterior probabilties.
	Maximum likelihood does not take prior into consideration (ignores the prior) so it is like being a Bayesian  while using some kind of a flat prior.

Q7. What is an Eigenvalue and Eigenvector?
A7. In linear algebra, an eigenvector or characteristic vector of a linear transformation is a non-zero vector that only changes by a scalar factor, when that linear transformation is applied to it. 

Q8. What is the curse of dimensionality?
A8. This exponential growth in data causes high sparsity in the data set and unnecessarily increases storage space and processing time for the particular modelling algorithm. This makes clustering etc very difficult. 2d clusters can't be generalized to 7d

Q9. How can non-linear relations between X (age) and Y (income) fit into a linear model?
A9. https://www.quora.com/How-can-non-linear-relations-between-X-age-and-Y-income-fit-into-a-linear-model
	By approximating values between a range.

Q10. What is “naive” in a naive Bayes classifier?
A10. A naive Bayes classifier assumes that the presence (or absence) of a particular feature of a class is unrelated to the presence (or absence) of any other feature, given the class variable.
	Doesn't constitute for independency between features.
	eg. a fruit may be considered to be an apple if it is red, round, and about 4" in diameter. Even if these features depend on each other or upon the existence of the other features, a naive Bayes classifier considers all of these properties to independently contribute to the probability that this fruit is an apple.

Q11. What is bayesian vs frequentist view points?
A11. Bayesian says that data is fixed and parameters need to be defined
	 frequentist says that parameters are fixed and data need to be randomly sampled.

Q12. Difference between Bayesian estimator and Maximum Likelihood?
A12. Maximum likelihood finds parameters which maximizes the probability of the data point to appear
	 Bayesian calculates the prosterior probabilty of data point given a parameter

Q13. How to ensure random sampling for A/B tests?
A13. Use stratified sampling. Divide the population into homogenous groups, then randomly sample from those groups. Reduces variance.

Q14. How to find the influence of a person on twitter?
A14. http://thenoisychannel.com/2009/01/13/a-twitter-analog-to-pagerank

Q15. Explain prior probability, likelihood and marginal likelihood in context of naiveBayes algorithm?
A15. Prior probability is the proportion of dependent (binary) variable in the data set. 
		eg. (number of spam = yes)/ total data points

	 Likelihood is the probability of classifying a given observation as 1 in presence of some other variable.
	 	eg. The probability that the word ‘FREE’ is used in previous spam message is likelihood

	 Marginal likelihood the probability that the word ‘FREE’ is used in any message.

Q16. How does regularization reduces overfitting?
A16. By reducing the bias of the model and restricting β.
	 Overfitting is caused when the model is too complicated, thus it gets built in the shape of the train data.
	 If we introduce a regularization, it restricts the model by limiting the space that the parameter vector β can live in. β is the estimator here.
	 So model is simplier and hence overfitting is reduced

Q17. In regression, which loss function is best suited when we have outliers?
A17. MAE is good for outliers, but is non differentiable at 0
     MSE is bad for outliers, as being squared, it gives very high importance to errors and makes model complicated
     Huber loss is a good mix, MSE near 0 and MAE towards outliers

Q18. What is Bayesian neural network?
A18. Standard neural network is equivalent to looking at the likelihood of the function. We fix the parameters and try to find them. This is the frequentist approach.
	 But is it right? -> we ignore any uncertainty that we may have in the proper weight values, as we use point estimates.
	 In Bayesian neural network, we have a Neural Network with a prior distribution in its weights. Hence we get a 'distribution' of answer rather than a single answer.

	 This takes care of both -> regularization and model selection without cross-validation.

Q19. Give an example of a case in which you run an A/B test, test wins with significant p-value, but you still choose to not make the change?
A19. Sample size too low. bigger the sample size more is the statistical significance of a computed figure


Q20. What does statistical significance mean?
A20. Statistical significance means that there is less chance of sampling error affecting the mean differences. It comes from data and the confidence intervals.

	 Statistical significance means that there is a probability that a relationship between two variables exists.
	 A practical significance means that there exists a relationship between two variables in the real world.

Q21. Steps for A/B Testing?
A21. a. Find the business goal : to improve the website
	 b. Find the KPI used to measure this goal : what to measure, click through rate
	 c. Get the metrics from the KPI
	 d. Select the elements to test : two versions of the submit button
	 e. Design the test : mean/proportion, sample size, significance level
	 f. Divide population : stratified random etc
	 g. Let the test accumulate data : don't stop in between if significance level is reached
	 h. Document the results and implement the changes if needed

Q22. Type 1 vs Type 2 errors?
A22. Type 1 error is when we reject the null hypothesis, but the null hypothesis is true
	 Type 2 error is when we do not reject the null hypothesis, but the null hypothesis is false.

Q23. What is Fourier Transform?
A23. Given a generic function, it decomposes the generic function into a superimposition of symmetric functions.

Q24. What is multi-colinearity and how to detect and fix it?
A24. Multi-colinearity : two or more highly correlated variables
	 Multi-colinearity is bad because X(t)X is not invertible (in case of perfect mc and rank is <n)
	 Otherwise, the variance of the model is high, because change in one variable drastically changes one or more variables. 
	 Multi-colinearity thus leads to overfitting

	 We can detect multicolinearity using the VIF(variance inflated factor) - how much variance is in the model

	 Remove multicolinearity by
	 	removing one of correlated variables
	 	PCA
	 	Ridge regression

Q25. Why use timeseries when we have regression?
A25. Because in time series, we forecast values, which is equal to extrapolating the data.
	 In trying to extrapolate, if we are using linear regression, we can only predict trend in one direction.
	 Also, in time series, future is based on past -> in regression we do not take this into account

Q26. Parametric vs non-parametric model?
A26. parametric models : y_i = b0 + b_i*x_i + e_i
     non parametric models : y_i = f(x_i)  +e_i

     parametric models are easy to interpret. and easier to make predictions
     non-parameteric models are more robust and doesn't bother too much about outliers.

Q27. What is bootstrap?
A27. Given a large dataset, we need to estimate a statistics from that sample dataset. But we have only one dataset.
	 Bootstrap randomly samples from that dataset and creates sub-datasets that we have seen. 
	 For these sub-datasets, we create statistics for each of the sub-samples. This gives us the distribution of the statistics.
	 Bootstrap is always performed with replacement. 
	 if there are 'n' samples in the dataset. We can perform 1000 bootstrap samplings
	 	for each iteration, take 'n' samples with replacement, and compute mean(or any other statistics)
	 we will have a distribution of 1000 means.
	 take mean of the distribution to calculate the bootstrap mean.

	 Even functions can be bootstrapped. eg. slope of a regression line.
	 Draw a distribution for slope of the regression lines.

Q28. What is local optimum vs global optimum?
A28. Local optimum is when a solution is ideal only when seen in the context of its neighbours.
     Whereas global optimum is when the solution is ideal across all data points

     Cost function is always decreasing till the local optimum is reached, but not necessarily after that.

     To avoid local optimum -> do multiple iterations. For example in k-means, run k-means multiple times and then take the solution with lowest cost

Q29. Precision, recall and ROC?
A29. Precision : out of the entries predicted 1, how many are actually 1. --> 1 - specificity
	 Recall : out of the entries actually 1, how many are predicted 1. --> sensitivity 
	 ROC = true positive vs false positive --> sensitivity vs specificity
	 AUC = area under ROC curve (this is more robust to class imbalance)

Q30. Power of statistical test?
A30. Type 1 Error = Rejecting null hypothesis when it is true = alpha
	 Type 2 Error = Not rejecting null hypothesis when it is false = Beta
	 Power = (1-Beta)
	 	   = P(X >= x | mean = mean of alternate hypothesis ie x_bar)  
	 	   = P(Z >= (x - x_bar)/(std/sqrt(n)))
	 	   = 1 - P (Z < (x - x_bar)/(std/sqrt(n)))

	 https://onlinecourses.science.psu.edu/stat414/book/export/html/245

	 If we have the power to begin with, eg 90%, we can calculate sample size

Q31. R2 vs MSE?
A31. R2 tells you about the goodness of fit. It essentially tells how much variability in response can be explained by your model. 
	 MSE tells us about the predictive power of the model. Used for predictive analysis vs descriptive analysis.

Q32. What is a Box-Cox transformation?
A32. Power transformation that tends to make the data normal
		y_new = (y^(lambda) - 1)/lambda
	When lambda = 0, it is a log transformation

Q33. How to handle outliers?
A33. 1. Windsorize :  make data within 5-95 percentile etc
	 2. Transformation : boxcox (where lambda = 0 => log transformation)
	 3. remove outliers

Q34. Is rotation necessary in PCA? If yes, Why? What will happen if you don’t rotate the components?
A34. Yes rotation is necessary because it maximizes the difference between variance captured by the component.
	 If we don’t rotate the components, the effect of PCA will diminish and we’ll have to select more number of components to explain variance in the data set.

Q35. How to reduce dimensionality for variables?
A35. For numerical variables, we look at correlation. Use PCA
	 For categorical variables, we look at chi-squared test to determine if the relationship between two categorical variables in the sample = relationship in population.
	 	Ho - no relation
	 	Ha - relation
	 Compare continuous and categorical variables -> ANCOVA (analysis of covariance)

Q36. What is the difference between covariance and correlation?
A36. Correlation - standarized form of covariance
	 Covariances are difficult to compare

Q37. What is R2, adjusted R2 and tolerance?
A37. R2 -> how much variance in the data is explained by the model  1 - (y - y_pred)^2 / (y - y_mean)^2
	 Adjusted R2 -> R2 scaled for high number of variables
	 Tolerance -> 1/VIF. indicator of multicollinearity. 

Q38. Reasons for train and test data being different?
A38. 1. sampling bias : the data distribution is static, but training samples are obtained obtained non-randomly, and with a bias.
	 2. Covariate shift aka population drift : Here the data is not static, with one population used as a training data, and another population used for testing. eg a drug tested on rats is given to a horses that may have significant differences.
	 3. Temporal changes : test is ahead in time than train
	
Q39. Why does PCA require column mean to be zero (column centric)?
A39. Centering the data is not a requirement; it does however simplify notation and computations. Covariance matrix when its not column centered = Cov = sum_for_i((x_i - mean) * (x_i - mean)T)
	 When column centered = Cov = sum_for_i(x_i * x_i_T)

	 1. We calculate the correlation matrix of feature columns and find eigenvectors of this matrix.
	 2. We take these multidimensional vectors (top k) and calculate the projection of all features on them.

Q40. What is eigenvalue and eigenvalue?
A40. an eigenvector is a non-zero vector that only changes by a scalar factor when that linear transformation is applied to it.
	 eigenvalue is the scalar factor that is multiplied to the eigenvector to get the original vector back

Q41. Why is mean imputation a bad idea?
A41. 1. brings down the variance of the model.
	 2. brings down correlation

Q42. An HIV test has a sensitivity of 99.7% and a specificity of 98.5%. A subject from a population of prevalence 0.1% receives a positive test result. What is the precision of the test (i.e the probability he is HIV positive)?
A42. Precision = P(Actual+ | Predicted+)
	 Using bayes rule.
	 P(Act+ | Pred+) = (P(Pred+ | Act+) * P(Act+)) / (P(Pred+ | Act+) * P(Act+) + P(Pred+ | Act-) * P(Act-))
	 		= (Recall_or_Sensitivity * Prevalence) / (Recall_or_Sensitivity * Prevalence + (1-Specificity) * (1-Prev))
	 		= 99*0.1 / (99*0.1 + (100-98.5)*(1-0.1))
	 		= 88

Q43. Geiger counter records 100 radioactive decays in 5 minutes. Find an approximate 95% interval for the number of decays per hour.
A43. Start by getting the 95% CI per 5 minute.
	 Poisson process with lambda = 100
	 95%CI = lambda +- 1.96 * sqrt(lambda) = 100 +- 1.96*10 = [80.4, 119.6]
	 CI per hour = [80.4, 119.6]*12 = (965, 1435)

Q44. The homicide rate in Scotland fell last year to 99 from 115 the year before. Is this reported change really networthy?
A44. Get the 95% CI of the homicide rate from previous year. If the new rate lies in the CI, then this is not significant enough.
	 Poisson's process. lambda = 115. 
	 95% CI : lambda +- 1.96 * sqrt(lambda) = 115 +- 1.96 * sqrt(115) = [94,137] 
	 Since 115 lies in the CI, we can't consider this significant.

Q45. In a study of emergency room waiting times, investigators consider a new and the standard triage systems. To test the systems, administrators selected 20 nights and randomly assigned the new triage system to be used on 10 nights and the standard system on the remaining 10 nights. They calculated the nightly median waiting time (MWT) to see a physician. The average MWT for the new system was 3 hours with a variance of 0.60 while the average MWT for the old system was 5 hours with a variance of 0.68. Consider the 95% confidence interval estimate for the differences of the mean MWT associated with the new system. Assume a constant variance. What is the interval? Subtract in this order (New System - Old System).
A45. mean = new - old = 3 - 5 = -2
	 var_1 = 0.68, var_2 = 0.6
	 n_1 = 10 = n_2
	 CI = mean +- 1.96 * sqrt(var_1/n_1 + var_2/n_2)
	 	= -2 +- 1.96 * sqrt(0.68/10 + 0.6/10)

	 if we are to assume constant variance, we can have a pooled variance calculated.
	 var_pooled = var_1*(n_1 - 1) + var_2*(n_2 - 1) / n_1 + n_2 -2
	 mean +- 1.96 * sqrt(var_pooled * (1/n_1 + 1/n_2))
	 

